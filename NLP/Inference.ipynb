{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01a26139",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Desktop\\Crochet_Project\\chatbot\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from torch import nn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# ================================\n",
    "# LOAD ENCODERS & SCALER\n",
    "# ================================\n",
    "product_encoder = joblib.load(\"../NLP/product_encoder.pkl\")\n",
    "character_encoder = joblib.load(\"../NLP/character_encoder.pkl\")\n",
    "\n",
    "scaler = joblib.load(\"../NLP/feature_scaler.pkl\")  # save during training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f7630de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# MODEL DEFINITION (same as training)\n",
    "# ================================\n",
    "class CrochetTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.fc = nn.Linear(768, 5)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.bert(ids, attention_mask=mask).last_hidden_state[:,0]\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a74a9ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 100/100 [00:00<00:00, 467.09it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]   \n",
      "\u001b[1mDistilBertModel LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "vocab_projector.bias    | UNEXPECTED |  | \n",
      "vocab_transform.weight  | UNEXPECTED |  | \n",
      "vocab_layer_norm.bias   | UNEXPECTED |  | \n",
      "vocab_transform.bias    | UNEXPECTED |  | \n",
      "vocab_layer_norm.weight | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# LOAD MODEL\n",
    "# ================================\n",
    "model = CrochetTransformer()\n",
    "model.load_state_dict(torch.load(\"../nlp/crochet_transformer.pt\"))\n",
    "model.eval()\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24175915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# INFERENCE FUNCTION\n",
    "# ================================\n",
    "def extract_attributes(text):\n",
    "    tokens = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        preds = model(tokens[\"input_ids\"], tokens[\"attention_mask\"]).numpy()\n",
    "\n",
    "    # reverse scaling\n",
    "    preds = preds[0]   # shape (5,)\n",
    "\n",
    "    # separate outputs\n",
    "    product_pred = preds[0]\n",
    "    height_pred = preds[1]\n",
    "    width_pred = preds[2]\n",
    "    colors_pred = preds[3]\n",
    "    character_pred = preds[4]\n",
    "\n",
    "    # inverse scale ONLY numeric values\n",
    "    numeric = scaler.inverse_transform([[height_pred, width_pred, colors_pred]])[0]\n",
    "\n",
    "    height = round(numeric[0])\n",
    "    width = round(numeric[1])\n",
    "    colors = round(numeric[2])\n",
    "\n",
    "    # categorical decoding\n",
    "    product_id = round(product_pred)\n",
    "    character_id = round(character_pred)\n",
    "\n",
    "    product = product_encoder.inverse_transform([product_id])[0]\n",
    "    character = character_encoder.inverse_transform([character_id])[0]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"product\": product,\n",
    "        \"height\": None if height == 0 else height,\n",
    "        \"width\": None if width == 0 else width,\n",
    "        \"colors\": None if colors == 0 else colors,\n",
    "        \"character\": None if character == \"0\" else character\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2929a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'product': 'keychain', 'height': 18, 'width': 18, 'colors': 4, 'character': 'flowers'}\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# QUICK TEST\n",
    "# ================================\n",
    "if __name__ == \"__main__\":\n",
    "        text = input(\"\\nYou: \")\n",
    "        print(extract_attributes(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
